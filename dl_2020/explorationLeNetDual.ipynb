{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\theop\\\\OneDrive\\\\Documents\\\\GitHub\\\\digit_fashion_nn\\\\dl_2020', 'C:\\\\Users\\\\theop\\\\Anaconda3\\\\python37.zip', 'C:\\\\Users\\\\theop\\\\Anaconda3\\\\DLLs', 'C:\\\\Users\\\\theop\\\\Anaconda3\\\\lib', 'C:\\\\Users\\\\theop\\\\Anaconda3', '', 'C:\\\\Users\\\\theop\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages', 'C:\\\\Users\\\\theop\\\\Anaconda3\\\\lib\\\\site-packages', 'c:\\\\users\\\\theop\\\\onedrive\\\\documents\\\\github\\\\ada_project\\\\src', 'C:\\\\Users\\\\theop\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\theop\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\theop\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\theop\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\theop\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('/lib/python3.7/site-packages')\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PILLOW_VERSION' from 'PIL' (C:\\Users\\theop\\Anaconda3\\lib\\site-packages\\PIL\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bd4cac111550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlc_practical_prologue\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mprologue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\digit_fashion_nn\\dl_2020\\dlc_practical_prologue.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msvhn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVHN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mphototour\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPhotoTour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfakedata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFakeData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msemeion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSEMEION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0momniglot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOmniglot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\fakedata.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVisionDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageEnhance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPILLOW_VERSION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0maccimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PILLOW_VERSION' from 'PIL' (C:\\Users\\theop\\Anaconda3\\lib\\site-packages\\PIL\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(device)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prologue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0c598a1dbf8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m (train_input,train_target,train_classes, \\\n\u001b[1;32m----> 4\u001b[1;33m  test_input,test_target,test_classes) = prologue.generate_pair_sets(N)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtrain_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prologue' is not defined"
     ]
    }
   ],
   "source": [
    "#Generating pairs of 14x14\n",
    "N=1000\n",
    "(train_input,train_target,train_classes, \\\n",
    " test_input,test_target,test_classes) = prologue.generate_pair_sets(N)\n",
    "\n",
    "train_input = train_input.to(device)\n",
    "test_input = test_input.to(device)\n",
    "train_target = train_target.to(device)\n",
    "test_target = test_target.to(device)\n",
    "print(train_input.size())\n",
    "print(train_target.size())\n",
    "print(train_classes.size())\n",
    "print(test_input.size())\n",
    "print(test_target.size())\n",
    "print(test_classes.size())\n",
    "print(test_input.narrow(0,200,100).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_(train_input,test_input):\n",
    "    \"\"\"Function to normalize the input\"\"\"\n",
    "    mu, std = train_input.mean(), train_input.std()\n",
    "    train_inputOut = train_input.sub_(mu).div_(std)\n",
    "    test_inputOut = test_input.sub_(mu).div_(std)\n",
    "    return train_inputOut, test_inputOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2, 14, 14])\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "train_input,test_input = norm_(train_input,test_input);\n",
    "print(train_input.size())\n",
    "print(train_input.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models :\n",
    "ConvNet (LeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining model\n",
    "class testNet(nn.Module):\n",
    "    def __init__(self,nb_hidden):\n",
    "        super(testNet, self).__init__()\n",
    "        #takes 2x14x14\n",
    "        #gives 32x12x12, 32x6x6 after maxpool\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3) \n",
    "        #takes 32x6x6, gives 64x4x4 then 64x2x2 after maxpool\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        #takes 64*2*2 = 254, gives nb_hidden\n",
    "        self.fc1 = nn.Linear(2*2*64, nb_hidden)\n",
    "        #takes nb_hidden, gives 10 classes\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2,stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2,stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 2*2 * 64)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class testNet2(nn.Module):\n",
    "    def __init__(self,nb_hidden):\n",
    "        super(testNet2, self).__init__()\n",
    "        #takes 2x14x14\n",
    "        #gives 32x12x12, 32x6x6 after maxpool\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3) \n",
    "        #takes 32x6x6, gives 64x6x6 then 64x3x3 after maxpool\n",
    "        self.conv2 = nn.Conv2d(32,32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32,64,kernel_size=1)\n",
    "        #takes 64*2*2 = 254, gives nb_hidden\n",
    "        self.fc1 = nn.Linear(2*2*64, nb_hidden)\n",
    "        #takes nb_hidden, gives 2 classes\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2,stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2,stride=2))\n",
    "        x = F.elu(self.conv3(x),alpha = 0.7)\n",
    "        x = F.relu(self.fc1(x.view(-1, 2*2 * 64)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class testNet3(nn.Module):\n",
    "    def __init__(self,nb_hidden):\n",
    "        super(testNet3, self).__init__()\n",
    "        #takes 2x14x14\n",
    "        #gives 32x12x12, 32x6x6 after maxpool\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3) \n",
    "        #takes 32x6x6, gives 64x6x6 then 64x3x3 after maxpool\n",
    "        self.conv2 = nn.Conv2d(32,32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32,64,kernel_size=1)\n",
    "        #takes 64*2*2 = 254, gives nb_hidden\n",
    "        self.fc1 = nn.Linear(2*2*64, nb_hidden)\n",
    "        #takes nb_hidden, gives 2 classes\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2,stride=2))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2,stride=2))\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 2*2 * 64)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class testNet4(nn.Module):\n",
    "    def __init__(self,nb_hidden):\n",
    "        super(testNet4, self).__init__()\n",
    "        #takes 2x14x14\n",
    "        #gives 32x12x12, 32x6x6 after maxpool\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3) \n",
    "        #takes 32x6x6, gives 64x6x6 then 64x3x3 after maxpool\n",
    "        self.conv2 = nn.Conv2d(32,32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32,64,kernel_size=1)\n",
    "        #takes 64*2*2 = 254, gives nb_hidden\n",
    "        self.fc1 = nn.Linear(2*2*64, nb_hidden)\n",
    "        #takes nb_hidden, gives 2 classes\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.dropout = nn.Dropout2d(0.38)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2,stride=2))\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2,stride=2))\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 2*2 * 64)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, nb_epochs, eta, mini_batch_size):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr = eta)\n",
    "    losses = []\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            \n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            losses.append(loss)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def compute_nb_errors(model,data_input,data_target,mini_batch_size):\n",
    "    nb_errors = 0;\n",
    "    model.to(device)\n",
    "    data_input, data_target = data_input.to(device),data_target.to(device)\n",
    "    \n",
    "    for b in range(0,data_input.size(0),mini_batch_size):\n",
    "        output = model(data_input.narrow(0,b,mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if data_target[b+k]!=predicted_classes[k]:\n",
    "                nb_errors += 1\n",
    "    \n",
    "    return nb_errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining stuff and running\n",
    "def run_test(model,nb_epochs,eta,mini_batch_size):\n",
    "    print(\"\"\"Using {} epochs, lr = {:.02f},Mini batch size = {}\"\"\".format(nb_epochs,eta,mini_batch_size))\n",
    "    model.to(device)\n",
    "    train_model(model, train_input, train_target,\n",
    "                nb_epochs, eta, mini_batch_size)\n",
    "    print('train_error {:.02f}% test_error {:.02f}% \\n'.format(\n",
    "                compute_nb_errors(model, train_input, train_target,mini_batch_size) / train_input.size(0) * 100,\n",
    "                compute_nb_errors(model, test_input, test_target,mini_batch_size) / test_input.size(0) * 100\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train_model with per epoch error print hidden here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#function to train AND print error per epoch\n",
    "#just for test\n",
    "def train_model_epoch_error(model, train_input, train_target, nb_epochs, eta, mini_batch_size):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr = eta)\n",
    "    losses = []\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        nb_errors = 0;\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            \n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            _, predicted_classes = torch.max(output, 1)\n",
    "            for k in range(mini_batch_size):\n",
    "                if train_target[b+k]!=predicted_classes[k]:\n",
    "                    nb_errors += 1\n",
    "            \n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            losses.append(loss)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch : {}, train_error {:.02f}%\".format(e,(100*(nb_errors/train_input.size(0)))))\n",
    "            \n",
    "#With epoch error\n",
    "def run_test_epoch(model,nb_epochs,eta,mini_batch_size):\n",
    "    print(\"Using {} epochs, lr = {:.02f}, Mini batch size = {}\".format(nb_epochs,\n",
    "                                                                        eta,\n",
    "                                                                        mini_batch_size,\n",
    "                                                                        ))\n",
    "    model.to(device)\n",
    "    train_model_epoch_error(model, train_input, train_target,\n",
    "                nb_epochs, eta, mini_batch_size)\n",
    "    \n",
    "    print('train_error {:.02f}% test_error {:.02f}% \\n'.format(\n",
    "                compute_nb_errors(model, train_input, train_target,mini_batch_size) / train_input.size(0) * 100,\n",
    "                compute_nb_errors(model, test_input, test_target,mini_batch_size) / test_input.size(0) * 100\n",
    "            )\n",
    "        )\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden : 10\n",
      "Using 150 epochs, lr = 0.10, Mini batch size = 50\n",
      "Epoch : 0, train_error 45.10%\n",
      "Epoch : 1, train_error 37.20%\n",
      "Epoch : 2, train_error 30.60%\n",
      "Epoch : 3, train_error 26.20%\n",
      "Epoch : 4, train_error 22.80%\n",
      "Epoch : 5, train_error 20.70%\n",
      "Epoch : 6, train_error 18.00%\n",
      "Epoch : 7, train_error 15.50%\n",
      "Epoch : 8, train_error 17.60%\n",
      "Epoch : 9, train_error 11.70%\n",
      "Epoch : 10, train_error 14.70%\n",
      "Epoch : 11, train_error 13.20%\n",
      "Epoch : 12, train_error 9.60%\n",
      "Epoch : 13, train_error 8.30%\n",
      "Epoch : 14, train_error 7.50%\n",
      "Epoch : 15, train_error 3.90%\n",
      "Epoch : 16, train_error 6.60%\n",
      "Epoch : 17, train_error 3.20%\n",
      "Epoch : 18, train_error 0.50%\n",
      "Epoch : 19, train_error 0.20%\n",
      "Epoch : 20, train_error 0.10%\n",
      "Epoch : 21, train_error 0.00%\n",
      "Epoch : 22, train_error 0.00%\n",
      "Epoch : 23, train_error 0.00%\n",
      "Epoch : 24, train_error 0.00%\n",
      "Epoch : 25, train_error 0.00%\n",
      "Epoch : 26, train_error 0.00%\n",
      "Epoch : 27, train_error 0.00%\n",
      "Epoch : 28, train_error 0.00%\n",
      "Epoch : 29, train_error 0.00%\n",
      "Epoch : 30, train_error 0.00%\n",
      "Epoch : 31, train_error 0.00%\n",
      "Epoch : 32, train_error 0.00%\n",
      "Epoch : 33, train_error 0.00%\n",
      "Epoch : 34, train_error 0.00%\n",
      "Epoch : 35, train_error 0.00%\n",
      "Epoch : 36, train_error 0.00%\n",
      "Epoch : 37, train_error 0.00%\n",
      "Epoch : 38, train_error 0.00%\n",
      "Epoch : 39, train_error 0.00%\n",
      "Epoch : 40, train_error 0.00%\n",
      "Epoch : 41, train_error 0.00%\n",
      "Epoch : 42, train_error 0.00%\n",
      "Epoch : 43, train_error 0.00%\n",
      "Epoch : 44, train_error 0.00%\n",
      "Epoch : 45, train_error 0.00%\n",
      "Epoch : 46, train_error 0.00%\n",
      "Epoch : 47, train_error 0.00%\n",
      "Epoch : 48, train_error 0.00%\n",
      "Epoch : 49, train_error 0.00%\n",
      "Epoch : 50, train_error 0.00%\n",
      "Epoch : 51, train_error 0.00%\n",
      "Epoch : 52, train_error 0.00%\n",
      "Epoch : 53, train_error 0.00%\n",
      "Epoch : 54, train_error 0.00%\n",
      "Epoch : 55, train_error 0.00%\n",
      "Epoch : 56, train_error 0.00%\n",
      "Epoch : 57, train_error 0.00%\n",
      "Epoch : 58, train_error 0.00%\n",
      "Epoch : 59, train_error 0.00%\n",
      "Epoch : 60, train_error 0.00%\n",
      "Epoch : 61, train_error 0.00%\n",
      "Epoch : 62, train_error 0.00%\n",
      "Epoch : 63, train_error 0.00%\n",
      "Epoch : 64, train_error 0.00%\n",
      "Epoch : 65, train_error 0.00%\n",
      "Epoch : 66, train_error 0.00%\n",
      "Epoch : 67, train_error 0.00%\n",
      "Epoch : 68, train_error 0.00%\n",
      "Epoch : 69, train_error 0.00%\n",
      "Epoch : 70, train_error 0.00%\n",
      "Epoch : 71, train_error 0.00%\n",
      "Epoch : 72, train_error 0.00%\n",
      "Epoch : 73, train_error 0.00%\n",
      "Epoch : 74, train_error 0.00%\n",
      "Epoch : 75, train_error 0.00%\n",
      "Epoch : 76, train_error 0.00%\n",
      "Epoch : 77, train_error 0.00%\n",
      "Epoch : 78, train_error 0.00%\n",
      "Epoch : 79, train_error 0.00%\n",
      "Epoch : 80, train_error 0.00%\n",
      "Epoch : 81, train_error 0.00%\n",
      "Epoch : 82, train_error 0.00%\n",
      "Epoch : 83, train_error 0.00%\n",
      "Epoch : 84, train_error 0.00%\n",
      "Epoch : 85, train_error 0.00%\n",
      "Epoch : 86, train_error 0.00%\n",
      "Epoch : 87, train_error 0.00%\n",
      "Epoch : 88, train_error 0.00%\n",
      "Epoch : 89, train_error 0.00%\n",
      "Epoch : 90, train_error 0.00%\n",
      "Epoch : 91, train_error 0.00%\n",
      "Epoch : 92, train_error 0.00%\n",
      "Epoch : 93, train_error 0.00%\n",
      "Epoch : 94, train_error 0.00%\n",
      "Epoch : 95, train_error 0.00%\n",
      "Epoch : 96, train_error 0.00%\n",
      "Epoch : 97, train_error 0.00%\n",
      "Epoch : 98, train_error 0.00%\n",
      "Epoch : 99, train_error 0.00%\n",
      "Epoch : 100, train_error 0.00%\n",
      "Epoch : 101, train_error 0.00%\n",
      "Epoch : 102, train_error 0.00%\n",
      "Epoch : 103, train_error 0.00%\n",
      "Epoch : 104, train_error 0.00%\n",
      "Epoch : 105, train_error 0.00%\n",
      "Epoch : 106, train_error 0.00%\n",
      "Epoch : 107, train_error 0.00%\n",
      "Epoch : 108, train_error 0.00%\n",
      "Epoch : 109, train_error 0.00%\n",
      "Epoch : 110, train_error 0.00%\n",
      "Epoch : 111, train_error 0.00%\n",
      "Epoch : 112, train_error 0.00%\n",
      "Epoch : 113, train_error 0.00%\n",
      "Epoch : 114, train_error 0.00%\n",
      "Epoch : 115, train_error 0.00%\n",
      "Epoch : 116, train_error 0.00%\n",
      "Epoch : 117, train_error 0.00%\n",
      "Epoch : 118, train_error 0.00%\n",
      "Epoch : 119, train_error 0.00%\n",
      "Epoch : 120, train_error 0.00%\n",
      "Epoch : 121, train_error 0.00%\n",
      "Epoch : 122, train_error 0.00%\n",
      "Epoch : 123, train_error 0.00%\n",
      "Epoch : 124, train_error 0.00%\n",
      "Epoch : 125, train_error 0.00%\n",
      "Epoch : 126, train_error 0.00%\n",
      "Epoch : 127, train_error 0.00%\n",
      "Epoch : 128, train_error 0.00%\n",
      "Epoch : 129, train_error 0.00%\n",
      "Epoch : 130, train_error 0.00%\n",
      "Epoch : 131, train_error 0.00%\n",
      "Epoch : 132, train_error 0.00%\n",
      "Epoch : 133, train_error 0.00%\n",
      "Epoch : 134, train_error 0.00%\n",
      "Epoch : 135, train_error 0.00%\n",
      "Epoch : 136, train_error 0.00%\n",
      "Epoch : 137, train_error 0.00%\n",
      "Epoch : 138, train_error 0.00%\n",
      "Epoch : 139, train_error 0.00%\n",
      "Epoch : 140, train_error 0.00%\n",
      "Epoch : 141, train_error 0.00%\n",
      "Epoch : 142, train_error 0.00%\n",
      "Epoch : 143, train_error 0.00%\n",
      "Epoch : 144, train_error 0.00%\n",
      "Epoch : 145, train_error 0.00%\n",
      "Epoch : 146, train_error 0.00%\n",
      "Epoch : 147, train_error 0.00%\n",
      "Epoch : 148, train_error 0.00%\n",
      "Epoch : 149, train_error 0.00%\n",
      "train_error 0.00% test_error 19.00% \n",
      "\n",
      "Hidden : 25\n",
      "Using 150 epochs, lr = 0.10, Mini batch size = 50\n",
      "Epoch : 0, train_error 45.40%\n",
      "Epoch : 1, train_error 36.10%\n",
      "Epoch : 2, train_error 31.00%\n",
      "Epoch : 3, train_error 24.40%\n",
      "Epoch : 4, train_error 20.80%\n",
      "Epoch : 5, train_error 18.00%\n",
      "Epoch : 6, train_error 15.30%\n",
      "Epoch : 7, train_error 15.70%\n",
      "Epoch : 8, train_error 10.90%\n",
      "Epoch : 9, train_error 10.10%\n",
      "Epoch : 10, train_error 10.10%\n",
      "Epoch : 11, train_error 8.90%\n",
      "Epoch : 12, train_error 4.90%\n",
      "Epoch : 13, train_error 3.20%\n",
      "Epoch : 14, train_error 5.40%\n",
      "Epoch : 15, train_error 3.20%\n",
      "Epoch : 16, train_error 0.80%\n",
      "Epoch : 17, train_error 0.10%\n",
      "Epoch : 18, train_error 0.00%\n",
      "Epoch : 19, train_error 0.00%\n",
      "Epoch : 20, train_error 0.00%\n",
      "Epoch : 21, train_error 0.00%\n",
      "Epoch : 22, train_error 0.00%\n",
      "Epoch : 23, train_error 0.00%\n",
      "Epoch : 24, train_error 0.00%\n",
      "Epoch : 25, train_error 0.00%\n",
      "Epoch : 26, train_error 0.00%\n",
      "Epoch : 27, train_error 0.00%\n",
      "Epoch : 28, train_error 0.00%\n",
      "Epoch : 29, train_error 0.00%\n",
      "Epoch : 30, train_error 0.00%\n",
      "Epoch : 31, train_error 0.00%\n",
      "Epoch : 32, train_error 0.00%\n",
      "Epoch : 33, train_error 0.00%\n",
      "Epoch : 34, train_error 0.00%\n",
      "Epoch : 35, train_error 0.00%\n",
      "Epoch : 36, train_error 0.00%\n",
      "Epoch : 37, train_error 0.00%\n",
      "Epoch : 38, train_error 0.00%\n",
      "Epoch : 39, train_error 0.00%\n",
      "Epoch : 40, train_error 0.00%\n",
      "Epoch : 41, train_error 0.00%\n",
      "Epoch : 42, train_error 0.00%\n",
      "Epoch : 43, train_error 0.00%\n",
      "Epoch : 44, train_error 0.00%\n",
      "Epoch : 45, train_error 0.00%\n",
      "Epoch : 46, train_error 0.00%\n",
      "Epoch : 47, train_error 0.00%\n",
      "Epoch : 48, train_error 0.00%\n",
      "Epoch : 49, train_error 0.00%\n",
      "Epoch : 50, train_error 0.00%\n",
      "Epoch : 51, train_error 0.00%\n",
      "Epoch : 52, train_error 0.00%\n",
      "Epoch : 53, train_error 0.00%\n",
      "Epoch : 54, train_error 0.00%\n",
      "Epoch : 55, train_error 0.00%\n",
      "Epoch : 56, train_error 0.00%\n",
      "Epoch : 57, train_error 0.00%\n",
      "Epoch : 58, train_error 0.00%\n",
      "Epoch : 59, train_error 0.00%\n",
      "Epoch : 60, train_error 0.00%\n",
      "Epoch : 61, train_error 0.00%\n",
      "Epoch : 62, train_error 0.00%\n",
      "Epoch : 63, train_error 0.00%\n",
      "Epoch : 64, train_error 0.00%\n",
      "Epoch : 65, train_error 0.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-1e4fd4af4ded>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hidden : {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mrun_test_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-04920d4b2afd>\u001b[0m in \u001b[0;36mrun_test_epoch\u001b[1;34m(model, nb_epochs, eta, mini_batch_size)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     train_model_epoch_error(model, train_input, train_target,\n\u001b[1;32m---> 35\u001b[1;33m                 nb_epochs, eta, mini_batch_size)\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     print('train_error {:.02f}% test_error {:.02f}% \\n'.format(\n",
      "\u001b[1;32m<ipython-input-63-04920d4b2afd>\u001b[0m in \u001b[0;36mtrain_model_epoch_error\u001b[1;34m(model, train_input, train_target, nb_epochs, eta, mini_batch_size)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mpredicted_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                     \u001b[0mnb_errors\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\richi\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epochs, eta = 150, 1e-1\n",
    "\n",
    "for mini_batch_size in [50,100]:\n",
    "    for hidden in [10,25,50,100,200]:\n",
    "        print(\"Hidden : {}\".format(hidden))\n",
    "        model = testNet(hidden)\n",
    "        run_test_epoch(model,nb_epochs,eta,mini_batch_size)\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden : 10\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 50\n",
      "train_error 0.00% test_error 19.70% \n",
      "\n",
      "Hidden : 25\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 50\n",
      "train_error 0.00% test_error 20.80% \n",
      "\n",
      "Hidden : 50\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 50\n",
      "train_error 0.00% test_error 19.90% \n",
      "\n",
      "Hidden : 100\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 50\n",
      "train_error 0.00% test_error 19.40% \n",
      "\n",
      "Hidden : 200\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 50\n",
      "train_error 0.00% test_error 18.70% \n",
      "\n",
      "Hidden : 10\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.00% \n",
      "\n",
      "Hidden : 25\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.50% \n",
      "\n",
      "Hidden : 50\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 100\n",
      "train_error 0.00% test_error 19.20% \n",
      "\n",
      "Hidden : 100\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 100\n",
      "train_error 0.00% test_error 19.10% \n",
      "\n",
      "Hidden : 200\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 100\n",
      "train_error 0.00% test_error 17.30% \n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "nb_epochs, eta = 200, 1e-1\n",
    "\n",
    "for mini_batch_size in [50,100]:\n",
    "    for hidden in [10,25,50,100,200]:\n",
    "        print(\"Hidden : {}\".format(hidden))\n",
    "        model = testNet2(hidden)\n",
    "        run_test(model,nb_epochs,eta,mini_batch_size)\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden : 4000\n",
      "Using 300 epochs, lr = 0.11,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.10% \n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "nb_epochs, eta = 300, 1.1e-1\n",
    "\n",
    "for mini_batch_size in [100]:\n",
    "    for hidden in [4000]:\n",
    "        print(\"Hidden : {}\".format(hidden))\n",
    "        model = testNet3(hidden)\n",
    "        run_test(model,nb_epochs,eta,mini_batch_size)\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testResNetBlock(nn.Module):\n",
    "    def __init__(self,nb_channels,kernel_size):\n",
    "        super(testResNetBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(nb_channels, nb_channels,\n",
    "                               kernel_size = kernel_size,\n",
    "                               padding = (kernel_size - 1) // 2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(nb_channels, nb_channels,\n",
    "                               kernel_size = kernel_size,\n",
    "                               padding = (kernel_size - 1) // 2)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.bn1(y)\n",
    "        y = F.relu(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.bn2(y)\n",
    "        y = y + x\n",
    "        y = F.relu(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "######################################################################\n",
    "\n",
    "class testResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, nb_residual_blocks, nb_channels,\n",
    "                 kernel_size = 3):\n",
    "        super(testResNet, self).__init__()\n",
    "\n",
    "        self.conv0 = nn.Conv2d(2,nb_channels,kernel_size=3)\n",
    "        self.resnet_blocks = nn.Sequential(\n",
    "            *(testResNetBlock(nb_channels, kernel_size)\n",
    "              for _ in range(nb_residual_blocks))\n",
    "        )\n",
    "        self.avg = nn.AvgPool2d(kernel_size=12)\n",
    "\n",
    "        self.fc = nn.Linear(nb_channels, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = self.resnet_blocks(x)\n",
    "        x = F.relu(self.avg(x))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class testResNet2(nn.Module):\n",
    "\n",
    "    def __init__(self, nb_residual_blocks, nb_channels,\n",
    "                 kernel_size = 3):\n",
    "        super(testResNet2, self).__init__()\n",
    "\n",
    "        self.conv0 = nn.Conv2d(2,nb_channels,kernel_size=1)\n",
    "        self.resnet_blocks = nn.Sequential(\n",
    "            *(testResNetBlock(nb_channels, kernel_size)\n",
    "              for _ in range(nb_residual_blocks))\n",
    "        )\n",
    "        self.avg = nn.AvgPool2d(kernel_size=14)\n",
    "\n",
    "        self.fc = nn.Linear(nb_channels, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv0(x))\n",
    "        nn.Dropout2d(0.15)\n",
    "        x = self.resnet_blocks(x)\n",
    "        x = F.relu(self.avg(x))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks 2, chans 20\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.90% \n",
      "\n",
      "blocks 2, chans 40\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 17.20% \n",
      "\n",
      "blocks 2, chans 60\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 15.30% \n",
      "\n",
      "blocks 5, chans 20\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.70% \n",
      "\n",
      "blocks 5, chans 40\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 17.70% \n",
      "\n",
      "blocks 5, chans 60\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 16.20% \n",
      "\n",
      "blocks 8, chans 20\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.40% \n",
      "\n",
      "blocks 8, chans 40\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.80% \n",
      "\n",
      "blocks 8, chans 60\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 16.80% \n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "nb_epochs, eta = 250, 0.9e-1\n",
    "\n",
    "for mini_batch_size in [100]:\n",
    "    for nb_blocks in [2,5,8]:\n",
    "        for nb_channels in [20,40,60]:\n",
    "            print(\"blocks {}, chans {}\".format(nb_blocks,nb_channels))\n",
    "            model = testResNet(nb_blocks,nb_channels)\n",
    "            run_test(model,nb_epochs,eta,mini_batch_size)\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks 2, chans 20\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.70% \n",
      "\n",
      "blocks 2, chans 40\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 17.30% \n",
      "\n",
      "blocks 2, chans 60\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 17.10% \n",
      "\n",
      "blocks 5, chans 20\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 19.90% \n",
      "\n",
      "blocks 5, chans 40\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.20% \n",
      "\n",
      "blocks 5, chans 60\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 15.80% \n",
      "\n",
      "blocks 8, chans 20\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.40% \n",
      "\n",
      "blocks 8, chans 40\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 18.70% \n",
      "\n",
      "blocks 8, chans 60\n",
      "Using 250 epochs, lr = 0.09,Mini batch size = 100\n",
      "train_error 0.00% test_error 16.50% \n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "nb_epochs, eta = 250, 0.9e-1\n",
    "\n",
    "for mini_batch_size in [100]:\n",
    "    for nb_blocks in [2,5,8]:\n",
    "        for nb_channels in [20,40,60]:\n",
    "            print(\"blocks {}, chans {}\".format(nb_blocks,nb_channels))\n",
    "            model = testResNet2(nb_blocks,nb_channels)\n",
    "            run_test(model,nb_epochs,eta,mini_batch_size)\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden : 50\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 50\n",
      "train_error 1.30% test_error 18.50% \n",
      "\n",
      "Hidden : 100\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 50\n",
      "train_error 0.20% test_error 19.40% \n",
      "\n",
      "Hidden : 200\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 50\n",
      "train_error 0.20% test_error 17.70% \n",
      "\n",
      "Hidden : 400\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 50\n",
      "train_error 0.30% test_error 19.70% \n",
      "\n",
      "Hidden : 50\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 100\n",
      "train_error 0.20% test_error 19.00% \n",
      "\n",
      "Hidden : 100\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 100\n",
      "train_error 0.40% test_error 19.10% \n",
      "\n",
      "Hidden : 200\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 100\n",
      "train_error 1.00% test_error 19.50% \n",
      "\n",
      "Hidden : 400\n",
      "Using 200 epochs, lr = 0.10,Mini batch size = 100\n",
      "train_error 0.30% test_error 19.00% \n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "nb_epochs, eta = 200, 1e-1\n",
    "\n",
    "for mini_batch_size in [50,100]:\n",
    "    for hidden in [50,100,200,400]:\n",
    "        print(\"Hidden : {}\".format(hidden))\n",
    "        model = testNet4(hidden)\n",
    "        run_test(model,nb_epochs,eta,mini_batch_size)\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
